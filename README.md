# Natural-Language-Processing
Methods for feature engineering


Deep Learning is Pattern Recognition applied to words, sentences and paragraphs.

Vectorizing text is the process of transforming text into numeric tensors.

Tokens are the different units into which you can break down text.

